# Learnings from Glean Interview Prep

**Date Created**: 2026-02-15
**Last Updated**: 2026-02-16
**Status**: Active

---

## Overview

Interview prep for Glean AI Outcomes Manager role, built in 11 minutes by reusing patterns from the Gap engagement. Demonstrated that the 5-phase interview prep methodology is repeatable and adaptable across role types (enabler vs. executor).

---

## Patterns Discovered

### Pattern 1: Enabler vs. Executor Positioning
**Description**: The same proof points (Palette, AWS GenAI, AWS Public Sector) work for both strategic/enabler roles and tactical/executor roles — only the framing changes.
**Context**: Gap = enabler (governance, adoption, strategy). Glean = executor (build agents, ship outcomes, measure results).
**Value**: Eliminates redundant research. Proof points are reusable assets.
**Reusability**: High — apply to every future interview. Classify role type first, then adjust framing.

### Pattern 2: Modular Materials > Monolithic Documents
**Description**: Breaking interview prep into 5-6 focused documents (package, research brief, cheat sheet, demo script, methodology) is superior to 1-2 large documents.
**Context**: Gap used 1-2 large docs. Glean used 6 modular docs. Glean approach was easier to navigate and rehearse from.
**Value**: Faster prep on interview day. Print cheat sheet, skim package, rehearse from demo script.
**Reusability**: High — use modular template for all future interview preps.

### Pattern 3: Research Depth Scales with Domain Familiarity
**Description**: Unfamiliar domains (Gap/retail) require deep research (8+ docs, 150KB). Familiar domains (Glean/AI SaaS) need streamlined research (5 docs, 80KB).
**Context**: Gap required retail landscape analysis, operating model research, etc. Glean required only company/product/market overview.
**Value**: Don't over-research familiar domains. Invest research time where knowledge gaps exist.
**Reusability**: High — calibrate research depth by domain familiarity assessment.

### Pattern 4: 4-Question Framework as Universal Demo Tool
**Description**: The 4-question method (pattern, data, repetitive, measurable) works as both an interview demo framework and a real customer engagement tool.
**Context**: Used in Glean demo scenario (sales enablement use case) and Palette agent design.
**Value**: Shows interviewer how you think AND how you'd work with their customers.
**Reusability**: High — use in every customer-facing role interview.

---

## Skills to Extract to /palette/skills/

- [x] **interview-prep-methodology**: 5-phase interview prep process (foundation → research → frameworks → validation → prep) → Used in METHODOLOGY_GAP_VS_GLEAN.md
- [ ] **customer-demo-scenario**: Template for walking through a customer engagement in an interview → Target: `/palette/skills/talent/customer-demo-scenario.md`

---

## Agent Performance Notes

### Argentavis (Research)
- **Successes**: Company research was thorough and well-structured
- **Failures**: Funding data was stale ($2.2B vs. actual $7.2B) — needed live verification
- **Improvements**: Research agent should flag data age and suggest verification for fast-moving companies

### Therizinosaurus (Build)
- **Successes**: Built complete modular prep package in 11 minutes. Materials were immediately usable.
- **Failures**: None significant
- **Improvements**: Could auto-generate a "freshness check" list of facts that need verification

---

## Metrics & Outcomes

### Time Investment
- **Research**: ~1 hour (reused Gap patterns)
- **Build**: 11 minutes (streamlined from Gap learnings)
- **Validation**: 30 minutes (informal self-check)
- **Total**: ~3 hours (including review and refinement)

### Quality Metrics
- **Completeness**: 100% (all interview scenarios covered)
- **Reusability**: 90% (methodology doc is directly reusable)
- **Fit Score**: 92% (role aligns strongly with experience)

### Key Insight
11-minute build time vs. Gap's multi-hour process proves methodology reuse works. The 5-phase template is the primary output, not just the interview materials.

---

## Next Steps

1. [ ] Conduct interview when scheduled
2. [ ] Document what worked and what didn't (post-interview debrief)
3. [ ] Extract customer-demo-scenario skill to /palette/skills/talent/
4. [ ] Promote interview-prep-methodology to reusable template
5. [x] Update stale research data (Glean valuation, Google Duet AI → Gemini)

---

## References

- [Methodology comparison](prep/METHODOLOGY_GAP_VS_GLEAN.md)
- [Interview package](prep/GLEAN_INTERVIEW_PACKAGE.md)
- [Research brief](prep/GLEAN_RESEARCH_BRIEF.md)
- [decisions.md](fde/decisions.md)
