# GAP AI STRATEGY â€” INTERVIEW CHEAT SHEET

---

## AWS ANCHOR STORY â€” "FROM BROADCAST TO BEHAVIOR CHANGE"


â€œI started my career in linguistics and systems thinking, which shaped how I think about complexity and structure. I spent eight years in academia before moving to AWS, where Iâ€™ve spent the last eleven years building and scaling AI-enabled enterprise systems.

At AWS, I was brought in to solve what I saw as a distribution problem, not a creation problem. We were generating massive amounts of enablement content, but sellers werenâ€™t using it because it wasnâ€™t aligned to their workflows or incentives.

I shifted the strategy from top-down broadcast to targeted activation â€” mapping incentives, personas, and job-level workflows before introducing tools. We built agentic systems and lightweight â€œrecipesâ€ that sellers could use immediately, and adoption followed behavior change.

My core belief is that AI should either enable something that wasnâ€™t previously possible or meaningfully enhance the human interaction at the center of the work. For Gap, that means starting with merchandisers, planners, and store managers â€” understanding their incentives and workflows before prescribing platforms â€” and designing AI around their reality, not the other way around.â€



*Lead with this. It proves you've already done this kind of transformation.*

### Problem at AWS

Enablement was broadcast and fragmented:
- Static HQ pages, mass emails, broad sessions
- Multiple tools (QuickSuite, Kiro, internal research) with no coherent path
- Sellers labeled "not technical enough" or "not adapting"

Meanwhile:
- Comp tied to precise form submissions
- Sales plays required narrative rehearsal
- New products launched weekly
- AI tools existed but were intimidating

**The gap wasn't technology â€” it was confidence, clarity, and relevance.**

### What You Did (5 Moves)

**1. Started With Sellers, Not Tools**
- Met PMs and field leaders to map SPIFs, comp rules, required forms, GEO/POD motions
- Built enablement aligned to their incentives:
  - "Use AI to fill this form correctly so you get paid"
  - "Use AI to rehearse this sales play before the call"
  - "Use AI to generate a pitch narrative tailored to this motion"

> **Bridge to Gap**: "At Gap, I'd start the same way: with merchandisers, planners, and store managers, mapping their incentives and workflows before prescribing any tools."

**2. Built Agentic Workflows for Yourself First**
- Automated your own reporting pipeline
- Built GEO + Job Title + Sales Play analytics views
- Set up retrieval flows to generate contextual enablement summaries
- Used research agents to audit relevance and citation quality
- Identified bias in outputs and tuned retrieval/vector strategy
- Never asked sellers to adopt workflows you hadn't battle-tested yourself

**3. Reduced Fear With 5-Minute Recipes**
- Short, practical workflows: "Generate a sales play narrative in 5 minutes," "Audit your form submission," "Use Kiro to rehearse a pitch"
- Live, copyable workflows instead of theory
- Turned AI from abstract concept into usable behavior

**4. Moved From Mass Promotion to Targeted Activation**
- No more "blast everyone"
- Targeted specific PODs and roles
- Custom Slack channels and tailored content
- Each group got the one thing that unlocked them

**5. Reframed Executive Perception**
- Pushback narrative: "Sellers don't know how to sell when it's not easy"
- Your view: intelligent operators trapped in fragmented systems, incentives misaligned, fear of AI with no safe practice
- You humanized adoption: live demos, cross-org meetings, assuming high intelligence, removing stigma

### Impact (Hard Numbers)

- **+17% attendance** (153 â†’ 179 per session)
- **+50% high-CSAT sessions** (>4.9)
- **+67% sales plays covered** (133 â†’ 222)
- Distribution moved to Zoom webinar; calendar holds removed
- Interactive HQ navigation and automated analytics pipeline built

**Most important behavior shift**:
Sellers stopped asking "What is this tool?" and started asking **"Can this help me win this deal?"**
That's behavior change, not just usage.

### Why This Maps Directly to Gap

- Enable non-technical users (sellers) to adopt AI confidently
- Design agentic workflows you run in production before evangelizing
- Tie AI to real incentives (compensation, deal success), not abstract adoption
- Shift from broadcast enablement to targeted activation
- Change executive narrative from "people problem" to "system and incentive problem"

> **Closing line**: "At AWS I took fragmented, top-down enablement and turned it into targeted, agentic workflows that sellers actually used. At Gap, I'd do the same for merchandisers and store associates â€” but now the stakes are inventory, margin, and customer experience instead of cloud deals."

---paradox ai

danial - marketing ai
new content

darko - customer work

meta - agile employee before. 

interview process

bert

sara digital 

daniel 



## AWS ANCHOR STORY â€” "FROM BROADCAST TO BEHAVIOR CHANGE"


Hi, Iâ€™m Michael. I started my career in comparitive linguistics and systems thinking, which shaped how I approach complexity and structure. After eight years in academia, I moved to Amazon, where Iâ€™ve spent the last eleven years building and scaling AI-enabled enterprise systems.

At AWS, I was brought in to solve what I saw as a distribution problem, not a creation problem. We were generating enormous amounts of enablement content and tools, but adoption lagged because they werenâ€™t aligned to seller incentives or workflows.

I shifted the approach from top-down broadcast to persona-based activation â€” starting with incentives and job-level realities before introducing technology. We built agentic workflows and simple, repeatable â€œrecipesâ€ that sellers could use immediately, and adoption followed behavior change.

My core belief is that AI should either enable something that wasnâ€™t possible before or meaningfully enhance the human interaction at the center of work.

At Gap, I would start the same way â€” with merchandisers, planners, and store managers â€” mapping their incentives and workflows before prescribing platforms, and designing AI around their reality rather than the other way around.



## THE PROBLEM (GAP)

- **$50M-$100M/year** operational waste (overstock, markdowns, manual tasks)
- **~200 AI models** and tools creating tool sprawl, no coherent system
- **60-70%** of store associate time on tasks, not customers
- Forecasting and pricing still driven by intuition instead of integrated, data-driven decisions

## ONE-SENTENCE SOLUTION

One agentic system that makes every employee more capable at their specific job â€” not 100 tools, not pure automation, not replacing people.

---
### 1. FDE Model, Not "AI Platform Project"
### 2. LVMH-Style Governance (Central + Brand Autonomy) MaIA (Maison Artificial Intelligence Assistant)
### 4. Behavior Change, Not Training Events
### 5. Budget Shrinks Because Tool Sprawl Dies
### 3. Operations-First, Brand-Safe

### 1. Seams Theory â€” Where the $50-100M Waste Comes From
**Anchor scenario**: "Old Navy store #247 has 200 extra units of a jacket. Today, forecasting, markdown, and replenishment react separately. By the time everything syncs, margin is gone. One agentic system can simultaneously: mark down 15% in that store, reduce the next buy by 30%, and reroute inbound units to the store that's selling out â€” one decision, coordinated."
### 2. Staffing Inversion â€” 2 People Doing What 5 Couldn't
> "The question isn't 'can we run stores with fewer people?' It's 'what new capabilities do those same people have when an assistant shows them cross-store inventory, demand signals, and next best actions in real time?'"
### 3. Data That Doesn't Exist Yet

Biggest forecasting gains don't come from re-analyzing old data; they come from data you don't have yet:
- TikTok/Instagram trend velocity 4-6 weeks before POS
- Micro-demand by weather and local events
- Cross-brand cannibalization (Old Navy vs Gap vs Athleta)
- Structured return reasons (fit, quality, expectation mismatch)
- Foot-traffic intent: not just counts, but what people looked at and walked away from

> "Everyone is trying to squeeze more out of yesterday's data. The real advantage is in creating new information streams Gap doesn't have today â€” intent, cross-brand cannibalization, micro-trends â€” and feeding them into the same system."

---

## 5 BIG IDEAS

### 1. FDE Model, Not "AI Platform Project"

Embed Forward-Deployed Engineers directly with business units (Old Navy, Gap, Banana Republic, Athleta). Palantir, Databricks, Accenture's ~30K FDEs all use this. 12-week pilots instead of 12-month platform builds. FDEs sit WITH the operators they serve; they don't throw tools over the wall.

> "Instead of building a huge 'AI platform' and hoping people come, we start by putting a small team directly inside merchandising and stores, and build what those people actually use within 12 weeks." To make success move faster, we do this in several stores at once with different pilots, and see where we get covergence of outcome.

### 2. LVMH-Style Governance (Central + Brand Autonomy)

Central: one secure AI platform, policies, observability, shared models and agents. Federated: each brand decides which use cases to prioritize and owns adoption. LVMH does this at 75 maisons with MaIA (~40K employees, 2M+ requests/month); Gap has 4 brands, so it's easier to coordinate.
> "LVMH runs a single internal assistant, MaIA (Maison Artificial Intelligence Assistant), across 75 maisons. Gap has four brands. A similar hub-and-spoke model here is not only possible, it's simpler."

> "We start where the ROI is clear and brand risk is low â€” back-of-house and associates â€” and earn the right to go customer-facing later."

### 4. Behavior Change, Not Training Events

5-minute recipes, not 2-hour workshops. Champions program (POD-level advocates) instead of forcing tools. Persona-specific UX: mobile-first for associates, desktop for buyers/merchandisers. Shadow AI usage as a demand signal, not something to punish.

> "The constraint isn't intelligence, it's hesitation. You fix that with short, repeatable workflows tied to their actual incentives, not with another mandatory training."

### 5. Budget Shrinks Because Tool Sprawl Dies

Year 1: targeted investment to prove value. Year 2: scale successful patterns. Year 3: sunset overlapping tools, consolidate into one coherent system.

> "By Year 3 the budget is 25-30% lower than Year 2, because we're deleting overlapping tools. We don't ask for more money every year; we reduce spend because the system is working."

### 3. Operations-First, Brand-Safe

Year 1: operations and internal tools. Year 2: scale across brands. Year 3: selectively customer-facing where risk is low and value proven. Avoid Amazon Just Walk Out (heavy human back office) and food chain voice AI (viral failures).

---

## YEAR 1 PILOTS (CONCRETE PLAN)

**Old Navy â€” Inventory Forecasting**
~$50K | 5-10 merchandisers, 100-200 SKUs | Goal: 15-20% forecast accuracy improvement | Benefit: ~$2-3M

**Gap â€” Store Associate AI Assistant**
~$75K | 5-10 stores, 50-100 associates | Mobile + voice (inventory, product info, policies) | Benefit: ~$1.75-3.5M

**Banana Republic â€” Markdown Optimization**
~$60K | 5-10 merchandisers, key assortments | Price elasticity modeling + coordinated markdowns | Benefit: ~$1.75-3.5M

**Rule**: All pilots are 12 weeks, with explicit kill criteria.

---

## 5 RISKS & MITIGATIONS

1. **Brand safety** â€” stay operations-first Year 1, no direct customer automation
2. **Operational** â€” human-in-the-loop, live A/B tests, instant rollback
3. **Compliance** â€” PII triage, privacy-by-design, audit trails
4. **Employee trust** â€” "amplification, not replacement," safe practice spaces, champions
5. **Financial** â€” phased funding, 12-week kill switch, conservative benefit estimates

---

## RETAIL COMPARABLES

- **Walmart**: major AI/logistics initiatives delivering large-scale savings and productivity gains
- **Zara**: legendary inventory + fast fashion; high full-price sell-through by tight data loop
- **Perry Ellis**: dramatic SKU launch time reduction with AI-assisted processes
- **LVMH**: MaIA shows one internal assistant can support ~40K employees across 75 brands

> "We're aiming for LVMH-style internal adoption at a company with a fraction of the complexity, and Walmart-style operational savings at about one sixty-fifth of their AI spend."

---

## "NO" FRAMEWORK

**Kill pilots after 12 weeks if**: no measurable improvement | DAU/WAU < 80% | realized ROI < 50% of projected | unmitigated risk appears | business unit leaders not engaged

**Explicitly say no to**: AI replacing employees | black-box models controlling prices or staffing | forced adoption | a dozen disconnected tools and vendor hype

---

## 3 OUT-OF-THE-BOX IDEAS (DIFFERENTIATORS)

### 1. Seams Theory â€” Where the $50-100M Waste Comes From

Not a people problem; it's a seams problem between teams and systems. Forecasting, markdown, supply, and stores optimize individually. No one agent sees end-to-end: demand â†’ buy â†’ allocate â†’ markdown â†’ replenishment.

**Anchor scenario**: "Old Navy store #247 has 200 extra units of a jacket. Today, forecasting, markdown, and replenishment react separately. By the time everything syncs, margin is gone. One agentic system can simultaneously: mark down 15% in that store, reduce the next buy by 30%, and reroute inbound units to the store that's selling out â€” one decision, coordinated."

**Layer 1**: this level of coordination is impossible without AI at Gap's scale.

### 2. Staffing Inversion â€” 2 People Doing What 5 Couldn't

Not arguing to cut heads. Arguing to invert what the same heads can do. From "ring transactions and tidy shelves" to:
- "We can see every nearby store's inventory in real time"
- "We can recognize a returning customer and pull things they're likely to love"
- "We can notice a micro-trend (rain jackets) and trigger a floor set shift"

> "The question isn't 'can we run stores with fewer people?' It's 'what new capabilities do those same people have when an assistant shows them cross-store inventory, demand signals, and next best actions in real time?'"

### 3. Data That Doesn't Exist Yet

Biggest forecasting gains don't come from re-analyzing old data; they come from data you don't have yet:
- TikTok/Instagram trend velocity 4-6 weeks before POS
- Micro-demand by weather and local events
- Cross-brand cannibalization (Old Navy vs Gap vs Athleta)
- Structured return reasons (fit, quality, expectation mismatch)
- Foot-traffic intent: not just counts, but what people looked at and walked away from

> "Everyone is trying to squeeze more out of yesterday's data. The real advantage is in creating new information streams Gap doesn't have today â€” intent, cross-brand cannibalization, micro-trends â€” and feeding them into the same system."

---

## TWO-LAYER FRAMEWORK

**Layer 1 â€” Impossible Without AI**
- Cross-system coordination (seams theory)
- Real-time cross-store and cross-brand views
- Trend velocity detection
- Cannibalization and intent detection

**Layer 2 â€” Augment Humans**
- More time with customers
- Faster, more confident decisions
- Better merch and pricing choices
- Champions teaching peers

---

## CLOSING LINE

"We're not building AI for AI's sake. We're making 10,000+ Gap employees more capable at their specific jobs. The budget shrinks because we did it right."



## KEY NUMBERS (3-YEAR VIEW)

| Metric | Value |
|--------|-------|
| 3-Year Investment | $7.2M-$7.8M |
| 3-Year Benefit | $37.9M-$65M |
| 3-Year ROI | 430-730% |
| Year 1 Ask | $1.6M-$1.7M |
| Year 1 ROI | 120-280% |
| Payback | < 1 month after go-live |
| Year 3 Budget | 25-30% lower than Year 2 |
| Team | 10-11 FTE (6 FDEs + support + leadership) |
| Pilots | 3 in Year 1, $185K total |

**Gap context**:
- Revenue ~ $15.1B (FY24)
- Gross margin ~ 41%, one of the best in 20 years
- Cash ~ $2.4-$2.6B on hand
- 8 consecutive quarters of market share gains


1ï¸âƒ£ How would you prioritize AI use cases across merchandising, HR, supply chain, and stores?

Executive Answer:

I prioritize using three lenses: measurable business impact, workflow integration feasibility, and risk profile.

First, I look for areas with clear economic signals â€” margin, inventory accuracy, markdown optimization, or time spent on repetitive tasks.

Second, I assess whether the AI can embed directly into existing workflows. If it requires behavior change without integration, adoption will stall.

Third, I evaluate brand, compliance, and operational risk. In Year 1, I focus on internal use cases where ROI is measurable and exposure is low.

I believe in proving value through tightly scoped pilots with explicit success metrics before scaling.

2ï¸âƒ£ What would your first 90 days look like?

Executive Answer:

Days 1â€“30: Diagnose. Map stakeholders, tool sprawl, data readiness, and workflow friction.

Days 30â€“60: Prioritize. Identify two to three pilots with measurable KPIs and clear ownership.

Days 60â€“90: Execute disciplined pilots with feedback loops and executive visibility.

The goal isnâ€™t scale in 90 days â€” itâ€™s clarity, alignment, and one tangible proof point that the operating model works.

3ï¸âƒ£ How do you ensure responsible, human-centered AI enablement?

Executive Answer:

Responsible AI starts with scope discipline. Not every workflow should be automated.

I design for augmentation over replacement, embed human-in-the-loop controls, establish clear data boundaries, and measure performance transparently.

Trust is a design constraint. When employees understand what the system can and cannot do, adoption accelerates.

4ï¸âƒ£ How do you measure ROI for enterprise AI initiatives?

Executive Answer:

I measure ROI across three categories: cost reduction, productivity lift, and revenue or margin impact.

For operational use cases, that might mean reduced manual time or improved forecast accuracy. For merchandising, improved sell-through or reduced markdown intensity.

I always define baseline metrics before launching pilots and track realized impact, not theoretical gains.

ROI should be visible, measurable, and tied to business KPIs â€” not just usage metrics.

5ï¸âƒ£ How do you handle executive pushback on AI investment?

Executive Answer:

I frame AI investment as a portfolio decision, not a moonshot.

Start small. Define measurable outcomes. Fund in phases.

If the pilot doesnâ€™t hit predefined thresholds, we stop. If it does, we scale.

That discipline reduces risk and builds executive confidence.

6ï¸âƒ£ How do you prevent tool sprawl?

Executive Answer:

Tool sprawl happens when experimentation isnâ€™t governed.

I recommend a centralized platform strategy with federated use-case ownership.

That means shared standards, observability, and security â€” but brand-level autonomy in prioritization.

We sunset overlapping tools as successful patterns emerge.

7ï¸âƒ£ How do you drive AI adoption among non-technical employees?

Executive Answer:

Adoption succeeds when AI is embedded into existing workflows and tied to incentives.

I focus on small, practical workflows â€” not large training sessions.

Champions at the team level are critical. When peers demonstrate value, adoption spreads organically.

8ï¸âƒ£ When should you NOT use AI?

Executive Answer:

When the workflow lacks clean data, when risk outweighs value, or when automation removes necessary human judgment.

AI should solve meaningful problems, not create novelty.

If a deterministic system works better, use it.

9ï¸âƒ£ How would you evaluate ChatGPT vs Copilot vs Claude for enterprise use?

Executive Answer:

I evaluate across four dimensions: capability, integration into existing enterprise systems, governance and compliance, and cost structure.

The right platform depends on workflow fit and ecosystem integration â€” not model hype.

Platform choice should follow operating model strategy.

ðŸ”Ÿ How do you balance centralization vs brand autonomy?

Executive Answer:

Centralize standards, security, and core platform infrastructure.

Federate use-case prioritization and adoption within brands.

This allows scale without suppressing brand differentiation.

11ï¸âƒ£ What are the biggest risks of AI in retail?

Executive Answer:

Brand safety, pricing errors, biased decision-making, and over-automation.

Retail margins are tight â€” small errors scale quickly.

Risk management and guardrails must precede scale.

12ï¸âƒ£ How do you embed AI into Workday or HR systems?

Executive Answer:

Start with employee-facing workflows â€” onboarding support, policy Q&A, learning recommendations.

Integrate via APIs, maintain clear data boundaries, and avoid creating shadow systems.

AI should enhance the system of record, not replace it.

13ï¸âƒ£ How do you ensure AI improves margin, not just productivity?

Executive Answer:

Tie AI directly to margin-linked KPIs â€” sell-through rate, markdown percentage, inventory turns.

If the use case doesnâ€™t connect to economic drivers, it shouldnâ€™t be prioritized.

14ï¸âƒ£ How do you scale from pilot to enterprise rollout?

Executive Answer:

Define success upfront. Measure impact. Document lessons.

Standardize governance and rollout playbooks.

Then scale deliberately â€” not emotionally.

15ï¸âƒ£ How do you handle resistance from middle management?

Executive Answer:

Resistance often reflects fear of loss of control.

I involve managers early, define success metrics collaboratively, and show how AI supports their teamâ€™s performance.

Ownership reduces resistance.

16ï¸âƒ£ What does â€œAI enablementâ€ mean to you?

Executive Answer:

It means making employees more capable at their specific jobs.

Not more tools. Not automation for its own sake.

Capability amplification.

17ï¸âƒ£ How do you prioritize across competing stakeholder demands?

Executive Answer:

Use a transparent scoring framework: impact, feasibility, risk, and data readiness.

Publish criteria. Make trade-offs visible.

That builds trust in prioritization decisions.

18ï¸âƒ£ How do you monitor AI system performance over time?

Executive Answer:

Track model performance metrics, usage trends, business impact metrics, and drift indicators.

AI isnâ€™t â€œlaunch and forget.â€ Itâ€™s monitor and iterate.

19ï¸âƒ£ How do you manage vendor relationships?

Executive Answer:

Avoid single-vendor dependence when possible.

Negotiate flexibility, ensure data portability, and align contracts to performance.

Vendor strategy should support long-term operating flexibility.

20ï¸âƒ£ What differentiates you from other AI strategists?

Executive Answer:

Iâ€™ve built and debugged production AI systems inside large enterprises.

I understand not just strategy, but adoption, governance, and real-world friction.

I design operating models that make AI usable â€” not just impressive.